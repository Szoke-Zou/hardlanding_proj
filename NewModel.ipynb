{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a2756-969e-4f9c-9530-63cc314a09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 包依赖\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5834587-f735-4762-bbb8-72dbfd33bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局变量\n",
    "file_feature = r\"clean_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271634ce-f0ad-4844-9496-5eb1e6e2612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型构建\n",
    "# feature_size                                 输入特征个数\n",
    "# temporal_size                                时间步长度\n",
    "# temporal_fc_hidden_size                      时间维度全连接层神经元个数\n",
    "# feature_fc_hidden_size                       特征维度全连接层神经元个数\n",
    "# lstm_layer                                   LSTM层个数\n",
    "# cnn_kernel_size                              1d卷积层卷积核大小\n",
    "\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, feature_size, temporal_size, temporal_fc_hidden_size, feature_fc_hidden_size, lstm_layer, cnn_kernel_size):\n",
    "        super(NewModel, self).__init__()\n",
    "        #参数初始化\n",
    "        self.feature_size = feature_size\n",
    "        self.temporal_size = temporal_size\n",
    "        self.temporal_fc_hidden_size = temporal_fc_hidden_size\n",
    "        self.feature_fc_hidden_size = feature_fc_hidden_size\n",
    "\n",
    "        #模型初始化\n",
    "        # Flatten, 用于展平数据\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        #时间维度全连接层\n",
    "        self.temporal_fc = nn.Sequential(\n",
    "            nn.Linear(1, self.temporal_fc_hidden_size)\n",
    "            nn.ReLU()\n",
    "            nn.Linear(self.temporal_fc_hidden_size, self.temporal_fc_hidden_size)\n",
    "        )\n",
    "        \n",
    "        #特征维度全连接层\n",
    "        self.feature_fc = nn.Sequential(\n",
    "            nn.Linear(1, self.feature_fc_hidden_size)\n",
    "            nn.ReLU()\n",
    "            nn.Linear(self.feature_fc_hidden_size, self.feature_fc_hidden_size)\n",
    "        )\n",
    "\n",
    "        #LSTM层\n",
    "        self.feature_demention = self.temporal_fc_hidden_size\n",
    "        self.cell_size = self.temporal_fc_hidden_size\n",
    "        self.lstm_layer = lstm_layer\n",
    "        self.lstm = nn.LSTM(input_size = self.feature_demention, hidden_size = self.cell_size, num_layers = self.lstm_layer, batch_first = True)\n",
    "        \n",
    "        #CNN层\n",
    "        self.cnnin = self.feature_size\n",
    "        self.cnn_kernel_size = cnn_kernel_size\n",
    "        self.cnn_padding = (cnn_kernel_size - 1)/2\n",
    "        self.conv1d = nn.Conv1d(in_channels = self.cnnin, out_channels = self.cnnin, kernel_size = self.cnn_kernel_size, padding = self.cnn_padding)\n",
    "        \n",
    "        #Sigmoid，用作非线性变换\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        #归一化\n",
    "        code\n",
    "        \n",
    "        #TA，时间注意力机制\n",
    "        code\n",
    "        \n",
    "        #MHA，多头注意力机制\n",
    "        code\n",
    "        \n",
    "        #全连接层\n",
    "        code\n",
    "\n",
    "        #Softmax，输出多类型概率\n",
    "        code\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #时间维度的全连接层Temporal_FC\n",
    "        #按列展平\n",
    "        x = x.transpose(1,2)\n",
    "        x2 = self.flatten(x)\n",
    "        x2 = x2.flatten() #将batch_size维度也一并展平，形成1维tensor\n",
    "        \n",
    "        time_matrix = [] \n",
    "        time_tensor = []\n",
    "        time_batch = []\n",
    "        count = 1\n",
    "        for i in x2:\n",
    "            data = i\n",
    "            data = data.unsqueeze(0)\n",
    "            fc_out = self.temporal_fc(data)\n",
    "            time_matrix.append(fc_out)\n",
    "            if count % self.temporal_size == 0:\n",
    "                matrix = torch.stack(time_matrix)\n",
    "                time_tensor.append(matrix)\n",
    "                time_matrix = []\n",
    "            if count % (self.temporal_size * self.feature_size) == 0:\n",
    "                tensor = torch.stack(time_tensor)\n",
    "                time_batch.append(tensor)\n",
    "                time_tensor = []\n",
    "            count += 1\n",
    "        time_batch = torch.stack(time_batch)\n",
    "        # time_batich = [batch_size, feature_size, temporal_size, temporal_fc_hidden_size]\n",
    "\n",
    "        #LSTM层\n",
    "        #循环遍历每一个batch\n",
    "        #特征数量对应torch中的batch_size\n",
    "        #temporal_size对应torch中的sequence length\n",
    "        #temporal_fc_hidden_size对应torch中的特征个数\n",
    "        lstm_outs = []\n",
    "        for f in range(time_batch.size(0):\n",
    "            sub_tensor = time_batch[f]\n",
    "            lstm_out, _ = self.lstm(sub_tensor) #此处输出的lstm_out的tensor与sub_tensor大小一致，可以进行矩阵加减\n",
    "            lstm_outs.append(lstm_out)\n",
    "        lstm_outs = torch.stack(lstm_outs)\n",
    "        \n",
    "        #时间维度的Add&Norm\n",
    "        sigmoid_time = self.sigmoid(time_batch)\n",
    "        sigmoid_lstm = self.sigmoid(lstm_outs)\n",
    "        TA_in = sigmoid_time + sigmoid_lstm\n",
    "        # TA_in: [batch_size, feature_size, temporal_size, temporal_fc_hidden_size]\n",
    "        \n",
    "        #时空注意力机制TA\n",
    "        code\n",
    "        \n",
    "        #特征维度的全连接层Feature_FC\n",
    "        #按行展平\n",
    "        x1 = self.flatten(x)\n",
    "        x1 = x1.flatten() #将batch_size维度也一并展平，形成1维tensor\n",
    "        \n",
    "        feature_matrix = [] \n",
    "        feature_tensor = []\n",
    "        feature_batch = []\n",
    "        count = 1\n",
    "        for i in x1:\n",
    "            data = i\n",
    "            data = data.unsqueeze(0)\n",
    "            fc_out = self.feature_fc(data)\n",
    "            feature_matrix.append(fc_out)\n",
    "            if count % self.feature_size == 0:\n",
    "                matrix = torch.stack(feature_matrix)\n",
    "                feature_tensor.append(matrix)\n",
    "                feature_matrix = []\n",
    "            if count % (self.feature_size * self.temporal_size) == 0:\n",
    "                tensor = torch.stack(feature_tensor)\n",
    "                feature_batch.append(tensor)\n",
    "                feature_tensor = []\n",
    "            count += 1\n",
    "        feature_batch = torch.stack(feature_batch)\n",
    "        # feature_batch = [batch_size, temporal_size, feature_size, feature_fc_hidden_size]\n",
    "        \n",
    "        #CNN层\n",
    "        cnn1d_outs = []\n",
    "        for f in range(feature_batch.size(0):\n",
    "            #[batch_size, feature_size, sequence] conv1d在最后一个维度卷积\n",
    "            sub_tensor = feature_batch[f]\n",
    "            cnn1d_out = self.conv1d(sub_tensor) #此处输出的conv1d_out的形状与sub_tensor形状一致，可以进行矩阵加减\n",
    "            cnn1d_outs.append(cnn1d_out)\n",
    "        cnn1d_outs = torch.stack(cnn1d_outs)\n",
    "        \n",
    "        #特征维度的Add&Norm\n",
    "        sigmoid_feature = self.sigmoid(feature_batch)\n",
    "        sigmoid_cnn = self.sigmoid(cnn1d_outs)\n",
    "        MHA_in = sigmoid_feature + sigmoid_cnn\n",
    "        # MHA_in: [batch_size, temporal_size, feature_size, feature_fc_hidden_size]\n",
    "        \n",
    "        #多头注意力机制MHA\n",
    "        code\n",
    "        \n",
    "        #Add\n",
    "        code\n",
    "        \n",
    "        #全连接层FC + Softmax 得到输出\n",
    "        code\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d17d7c-8f7a-418d-b8ce-c307d5ecbf49",
   "metadata": {},
   "source": [
    "![jupyter](./模型流程图.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a825d488-f648-439f-9b54-e521297c16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "    def __init__(self, feature_size, temporal_size, temporal_fc_hidden_size, n):\n",
    "        super(NewModel, self).__init__()\n",
    "\n",
    "        self.feature_size = feature_size\n",
    "        self.temporal_size = temporal_size\n",
    "        self.temporal_fc_hidden_size = temporal_fc_hidden_size\n",
    "        self.n = n\n",
    "\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.temporal_fc = nn.Sequential(\n",
    "            nn.Linear(1, self.temporal_fc_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.temporal_fc_hidden_size, self.n)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):   \n",
    "        #按列展平\n",
    "        x = x.transpose(1,2)\n",
    "        x2 = self.flatten(x)\n",
    "        x2 = x2.flatten() #将batch_size维度也一并展平，形成1维tensor\n",
    "\n",
    "        #时间维度的全连接层Temporal_FC\n",
    "        time_matrix = [] \n",
    "        time_tensor = []\n",
    "        time_batch = []\n",
    "        count = 1\n",
    "        for i in x2:\n",
    "            data = i\n",
    "            data = data.unsqueeze(0)\n",
    "            fc_out = self.temporal_fc(data)\n",
    "            time_matrix.append(fc_out)\n",
    "            if count % 20 == 0:\n",
    "                matrix = torch.stack(time_matrix)\n",
    "                time_tensor.append(matrix)\n",
    "                time_matrix = []\n",
    "            if count % (self.temporal_size * self.feature_size) == 0:\n",
    "                tensor = torch.stack(time_tensor)\n",
    "                time_batch.append(tensor)\n",
    "                time_tensor = []\n",
    "            count += 1\n",
    "        time_batch = torch.stack(time_batch)\n",
    "        \n",
    "        return time_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e360ad5-cf4c-4542-a451-c3dd984cb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创造数据\n",
    "data = torch.randn(2,100,20)\n",
    "model = NewModel(20,100,10,10)\n",
    "\n",
    "model.train()\n",
    "total_out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411d5391-2be4-450e-be50-b2ed49ccdc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 20, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "541027cc-0c2e-4783-bbeb-32d6b944c5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3896e+00,  2.5180e-01, -4.4530e-01,  ..., -2.6253e-01,\n",
       "           3.1068e-01, -5.9803e-01],\n",
       "         [ 1.9354e-01,  5.1342e-01,  4.9294e-02,  ...,  1.2007e+00,\n",
       "          -2.1513e+00,  7.1522e-01],\n",
       "         [ 4.7915e-01,  2.1839e-01,  3.8866e-01,  ...,  8.0404e-01,\n",
       "           8.7054e-01,  2.6725e-01],\n",
       "         ...,\n",
       "         [ 8.7002e-02,  4.2814e-01,  5.6115e-01,  ..., -1.5945e-01,\n",
       "          -1.9266e+00,  1.1306e-01],\n",
       "         [-1.5509e+00,  7.9575e-02, -1.1222e+00,  ..., -5.1988e-01,\n",
       "           3.2378e-01,  1.0980e-01],\n",
       "         [ 1.1727e+00,  4.6077e-01, -6.1920e-01,  ..., -3.3946e-01,\n",
       "          -6.0177e-01, -1.2405e+00]],\n",
       "\n",
       "        [[ 1.6218e+00,  1.3591e+00, -1.6697e-01,  ...,  1.2692e+00,\n",
       "          -1.0682e+00,  2.4145e+00],\n",
       "         [ 7.3825e-01, -8.5672e-01, -3.2349e-01,  ..., -1.6664e-01,\n",
       "           1.1788e-01, -7.2712e-02],\n",
       "         [-1.3064e+00, -3.6120e-01, -4.7639e-01,  ...,  4.2178e-01,\n",
       "           2.0579e+00, -9.3695e-01],\n",
       "         ...,\n",
       "         [ 2.8061e-01,  1.9591e+00, -6.0753e-01,  ..., -9.9177e-01,\n",
       "           8.4346e-01, -1.9388e+00],\n",
       "         [-2.0580e+00,  3.9395e-01,  8.7787e-01,  ...,  7.3390e-01,\n",
       "          -2.1963e+00,  4.8393e-04],\n",
       "         [-1.9043e-01, -6.3750e-01, -1.3487e+00,  ...,  1.9412e+00,\n",
       "          -5.3237e-01,  2.4076e+00]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fab4efb-5ebc-43e2-884f-57eaa83c8903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 100, 10])\n",
      "torch.Size([2, 100, 20])\n"
     ]
    }
   ],
   "source": [
    "print(total_out.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140d79e-cb22-4b5c-bbf5-ddc5be068c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
