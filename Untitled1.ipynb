{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185f9e3d-7ec9-4a0d-87b4-f2f92c498c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 包依赖\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc679e9-0d03-4e67-a03b-e94e82d06f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CNN+LSTM+自互注意力模型\n",
    "#   Classification Model\n",
    "\n",
    "# params：\n",
    "# feature_size                                 输入特征个数 21个\n",
    "# temporal_size                                时间步长度  101个时间步\n",
    "# cnn_kernel_size                              卷积核长度\n",
    "# cnn_kernel_num                               卷积核个数\n",
    "# lstm_layer                                   LSTM层个数\n",
    "# self_att_hide                                自注意力层神经元数量\n",
    "# n                                            相同时间内，选取前n个分数最高的特征；相同特征下，选取前n个分数最高的时间\n",
    "# m                                            选取对单一特征，单一时间片段下，影响最大的前m个任意时间片段下的任意特征\n",
    "\n",
    "class CnnLstmModel(nn.Module):\n",
    "    def __init__(self, feature_size, temporal_size, cnn_kernel_size, cnn_kernel_num, lstm_layer, self_att_dim, inter_att_dim, n, m):\n",
    "        super(CnnLstmModel, self).__init__()\n",
    "        \n",
    "        # init param\n",
    "        self.feature_size = feature_size\n",
    "        self.temporal_size = temporal_size\n",
    "        self.cnn_kernel_size = cnn_kernel_size\n",
    "        self.cnn_kernel_num = cnn_kernel_num\n",
    "        self.lstm_layer = lstm_layer\n",
    "        self.self_att_dim = self_att_dim\n",
    "        self.inter_att_dim = inter_att_dim\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.dim = self.n * (self.feature_size + self.temporal_size)\n",
    "        \n",
    "        # CNN-layer:\n",
    "        # 输入:[batch_size, feature_size, temporal_size]\n",
    "        # 输出:[batch_size, feature_size * cnn_kernel_num, temporal_size]\n",
    "        self.cnnin = self.feature_size\n",
    "        self.cnnout = self.feature_size * self.cnn_kernel_num\n",
    "        self.cnn_padding = (self.cnn_kernel_size - 1) / 2\n",
    "        self.cnn = nn.Conv1d(\n",
    "            in_channels= self.cnnin, \n",
    "            out_channels= self.cnnout, \n",
    "            kernel_size= self.cnn_kernel_size, \n",
    "            stride= 1, \n",
    "            padding = self.cnn_padding\n",
    "        )\n",
    "        \n",
    "        # LSTM-layer:\n",
    "        # 输入:[feature_size, temporal_size， cnn_kernel_num] 需要转置操作\n",
    "        # 输出 = 输入。需要设置 hidden_size = cnn_kernel_num\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size= self.cnn_kernel_num,\n",
    "            hidden_size = self.cnn_kernel_num,\n",
    "            num_layers = self.lstm_layer,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        #Add&Norm\n",
    "\n",
    "        # Self-Attention:\n",
    "        # 输入:[batch_size, feature_size, temporal_size, cnn_kernel_num]\n",
    "        # 输出:[batch_size, feature_size, temporal_size, 1]\n",
    "        self.self_att_score = 1\n",
    "        self.self_att = nn.Sequential(\n",
    "            nn.Linear(self.cnn_kernel_num, self.self_att_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.self_att_dim, self.self_att_score)\n",
    "        )\n",
    "        \n",
    "        # Inter-Attention\n",
    "        # 输入: \n",
    "        #     1.CNN+LSTM的输出结果: [batch_size, feature_size, temporal_size, cnn_kernel_num]\n",
    "        #     2.选择后的Self-Attention的输出结果: [batch_size, (feature_size + temporal_size) * n, 1, cnn_kernel_num]\n",
    "        # 输出: [batch_size, (feature_size + temporal_size)*n*(m+1), 1, cnn_kernel_num]\n",
    "        # K:\n",
    "        # K的输入:[batch_size, feature_size, temporal_size, cnn_kernel_num]\n",
    "        # K的输出:[batch_size, feature_size, temporal_size, inter_att_dim]\n",
    "        self.k = nn.Sequential(\n",
    "            nn.Linear(self.cnn_kernel_num, self.inter_att_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.inter_att_dim, self.inter_att_dim)\n",
    "        )\n",
    "        # Q:\n",
    "        # Q的输入:[batch_size, (feature_size + temporal_size) * n, 1, cnn_kernel_num]\n",
    "        # Q的输出:[batch_size, (feature_size + temporal_size) * n, 1, inter_att_dim]\n",
    "        self.q = nn.Sequential(\n",
    "            nn.Linear(self.cnn_kernel_num, self.inter_att_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.inter_att_dim, self.inter_att_dim)\n",
    "        )\n",
    "        \n",
    "\n",
    "        #dense-layer\n",
    "        # 输入:[batch_size, n*(temporal_size+ feature_size), (m+1), cnn_kernel_num]\n",
    "        # 输出:[batch_size, class_size]\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # 第一层卷积:保持不变\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.dim,        # 输入通道数\n",
    "                out_channels=self.dim,       # 输出通道数\n",
    "                kernel_size=(3, 3),          # 卷积核大小\n",
    "                padding=1                    # 填充以保持空间维度\n",
    "            ),\n",
    "            nn.BatchNorm2d(self.dim),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),  # 池化减少空间维度\n",
    "            \n",
    "            # 第二层卷积:缓慢增加\n",
    "            nn.Conv2d(self.dim, self.dim * 2, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(self.dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            \n",
    "            # 第三层卷积\n",
    "            nn.Conv2d(self.dim * 2, 256, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # 全局平均池化\n",
    "        )\n",
    "        # [batch_size, 256, 1, 1]\n",
    "        \n",
    "        # 全连接分类层\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        \n",
    "        #softmax\n",
    "        self.softmax = nn.softmax(dim = -1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x:[batch_size, temporal_size, feature_size]\n",
    "        ### cnn layer\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # x:[batch_size, feature_size, temporal_size]\n",
    "        \n",
    "        x = self.cnn(x)\n",
    "        # x:[batch_size, feature_size * cnn_kernel_num, temporal_size]\n",
    "        \n",
    "        x = x.view(x.size(0), self.feature_size, self.cnn_kernel_num, x.size(2))\n",
    "        # x:[batch_size, feature_size, cnn_kernel_num, temporal_size]\n",
    "        \n",
    "        cnn_out = x.permute(0, 1, 3, 2)\n",
    "        # cnn_out:[batch_size, feature_size, temporal_size, cnn_kernel_num]\n",
    "\n",
    "\n",
    "        \n",
    "        ### lstm layer\n",
    "        x = cnn_out.view(cnn_out.size(0) * cnn_out.size(1), cnn_out.size(2), cnn_out.size(3))\n",
    "        # x:[batch_size * feature_size, temporal_size, cnn_kernel_num]\n",
    "        \n",
    "        x = self.lstm(x)\n",
    "        # x:[batch_size * feature_size, temporal_size, cnn_kernel_num]\n",
    "        \n",
    "        lstm_out = x.view(self.batch_size, self.feature_size, x.size(1), x.size(2))\n",
    "        # lstm_out:[batch_size, feature_size, temporal_size, cnn_kernel_num]\n",
    "\n",
    "\n",
    "        \n",
    "        ###cnn和lstm层结果的归一化  \n",
    "        union_out = cnn_out + lstm_out\n",
    "\n",
    "\n",
    "        \n",
    "        ### self-att layer\n",
    "        x = union_out.view(-1, self.cnn_kernel_num)\n",
    "        # x:[batch_size * feature_size * temporal_size, cnn_kernel_num]\n",
    "        \n",
    "        x = self.self_att(x)\n",
    "        # x:[batch_size * feature_size * temporal_size, 1]\n",
    "        \n",
    "        score = x.view(self.batch_size, self.feature_size, self.temporal_size)\n",
    "        # score:[batch_size, feature_size, temporal_size]\n",
    "\n",
    "\n",
    "\n",
    "        ## 同一时间维度选取得分最高的前n个特征\n",
    "        x = score.permute(0, 2, 1)\n",
    "        # x:[batch_size, temporal_size, feature_size]\n",
    "\n",
    "        temporal_topn_score, temporal_topn_indices = torch.topk(x, self.n, dim = 2)\n",
    "        # temporal_topn_score, temporal_topn_indices:[batch_size, temporal_size, n]\n",
    "\n",
    "        temporal_expanded_indices = temporal_topn_indices.unsqueeze(-1).expand(-1, -1, -1, self.cnn_kernel_num)\n",
    "        # temporal_expanded_indices:[batch_size, temporal_size, n, cnn_kernel_num]\n",
    "\n",
    "        temporal_topn_values = torch.gather(union_out, 2, temporal_expanded_indices)\n",
    "        # temporal_topn_values:[batch_size, temporal_size, n, cnn_kernel_num]\n",
    "        \n",
    "        ## 同一特征维度选取得分最高的前n个时间\n",
    "        feature_topn_score, feature_topn_indices = torch.topk(score, self.n, dim = 2)\n",
    "        # feature_topn_score, feature_topn_indices:[batch_size, feature_size, n]\n",
    "\n",
    "        feature_expanded_indices = feature_topn_indices.unsqueeze(-1).expand(-1, -1, -1, self.cnn_kernel_num)\n",
    "        # feature_expanded_indices:[batch_size, feature_size, n, cnn_kernel_num]\n",
    "\n",
    "        feature_topn_values = torch.gather(union_out, 2, feature_expanded_indices)\n",
    "        # feature_topn_values:[batch_size, feature_size, n, cnn_kernel_num]\n",
    "\n",
    "\n",
    "        ### inter-att layer\n",
    "        #待定\n",
    "        topn_values = []\n",
    "        # topn_values:[batch_size, (feature_size + temporal_size) * n, cnn_kernel_num]\n",
    "\n",
    "        ## \n",
    "        x = union_out.view(union_out.size(0) * union_out.size(1) * union_out.size(2), union_out.size(3))\n",
    "        # x:[batch_size * feature_size * temporal_size, cnn_kernel_num]\n",
    "\n",
    "        x = self.k(x)\n",
    "        # x:[batch_size * feature_size * temporal_size, inter_att_dim]\n",
    "        k = x.view(self.batch_size, self.feature_size, self.temporal_size, -1)\n",
    "        # k:[batch_size, feature_size, temporal_size, inter_att_dim]\n",
    "\n",
    "        x = topn_values.view(topn_values.size(0) * topn_values.size(1), topn_values.size(2))\n",
    "        # x:[batch_size * (feature_size + temporal_size) * n, cnn_kernel_num]\n",
    "        \n",
    "        x = self.q(x)\n",
    "        # x:[batch_size * (feature_size + temporal_size) * n, inter_att_dim]\n",
    "        \n",
    "        q = x.view(self.batch_size, -1, x.size(1))\n",
    "        # q:[batch_size, (feature_size + temporal_size) * n, inter_att_dim]\n",
    "        \n",
    "        inter_att_score = torch.einsum('bftd,bqd->bqft', k, q)\n",
    "        # inter_att_score:[batch_size, (feature_size + temporal_size) * n, feature_size, temporal_size]\n",
    "\n",
    "        #初始化结果张量\n",
    "        dim1 = (self.feature_size + self.temporal_size) * self.n\n",
    "        inter_att_result = torch.zeros(self.batch_size, dim1, self.m, self.cnn_kernel_num)\n",
    "        for b in range(self.batch_size):\n",
    "            for d in range(dim1):\n",
    "                # 获取当前注意力分数矩阵 [feature_size, temporal_size]\n",
    "                att_matrix = inter_att_score[b, d]\n",
    "\n",
    "                # 展平注意力矩阵并获取前m个最大值的索引\n",
    "                flat_att = att_matrix.view(-1)\n",
    "                topk_values, topk_indices = torch.topk(flat_att, m, dim=0)\n",
    "\n",
    "                # 将扁平索引转换为二维索引 (feature_idx, temporal_idx)\n",
    "                feature_indices = topk_indices // temporal_size\n",
    "                temporal_indices = topk_indices % temporal_size\n",
    "                \n",
    "                # 从union_out中提取对应的特征\n",
    "                for i, (f_idx, t_idx) in enumerate(zip(feature_indices, temporal_indices)):\n",
    "                    result[b, d, i] = union_out[b, f_idx, t_idx]\n",
    "        # inter_att_result = [batch_size, (feature_size + temporal_size) * n, m, cnn_kernel]\n",
    "\n",
    "        topn_values_expanded = topn_values.unsqueeze(2)\n",
    "        # [batch_size, dim1, cnn_kernel_num] -> [batch_size, dim1, 1, cnn_kernel_num]\n",
    "\n",
    "        combined = torch.cat([topn_values_expanded, inter_att_result], dim=2)\n",
    "        # combined = [batch_size, dim1, m+1, cnn_kernel_num]\n",
    "        conv2d_out = self.conv_layer(combined)\n",
    "        conv2d_out = conv2d_out.view(conv2d_out.size(0), -1)\n",
    "        fc_out = self.fc(conv2d_out)\n",
    "        # fc_out = [batch_size, num_classes]\n",
    "        out = self.softmax(fc_out)\n",
    "\n",
    "        return out\n",
    "        # cnn-layer:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff831473-bba4-4925-90e7-9ace23d358be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
